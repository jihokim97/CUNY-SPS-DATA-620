{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c84abeb",
   "metadata": {},
   "source": [
    "# Week 8 | Project - 3\n",
    "Group 4: Joshua Hummell, Jiho Kim, Scott Reed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db521f06",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=75mxuo8w-UE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a0ce2",
   "metadata": {},
   "source": [
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python,\n",
    "and any features you can think of, build the best name gender classifier you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5384c070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists.\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import random\n",
    "from nltk.classify.naivebayes import NaiveBayesClassifier\n",
    "import nltk.classify\n",
    "\n",
    "spec = importlib.util.find_spec('nltk')\n",
    "if spec is None:\n",
    "    print(package_name +\" is not installed. Installing:\")\n",
    "    nltk.download()\n",
    "else:\n",
    "    (print(\"Exists.\"))\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "444ae781",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "          [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "random.Random(512).shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec496fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dolorita', 'female'), ('Kennedy', 'male'), ('Nessi', 'female'), ('Karie', 'female'), ('Florie', 'female')]\n"
     ]
    }
   ],
   "source": [
    "print(names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01b08e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryFeatures(f, c = NaiveBayesClassifier, final= False):\n",
    "     #Begin by splitting the Names Corpus into three subsets: 500 words for the test set, \n",
    "     #500 words for the devtest set, and the remaining 6900 words for the training set.\n",
    "    test_names, devtest_names, train_names = names[:499], names[500:999], names[1000:]\n",
    "    \n",
    "    train_set = [(f(n), g) for (n,g) in train_names]\n",
    "    \n",
    "    devtest_set = [(f(n), g) for (n,g) in devtest_names]\n",
    "    \n",
    "    test_set = [(f(n), g) for (n,g) in test_names]\n",
    "    \n",
    "    classifier = c.train(train_set) \n",
    "    \n",
    "    testSet = devtest_set\n",
    "    \n",
    "    if(final):\n",
    "        testSet = test_set\n",
    "        \n",
    "    return (nltk.classify.accuracy(classifier, train_set),nltk.classify.accuracy(classifier, testSet)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bff4fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.857286866359447, 0.8156312625250501)\n"
     ]
    }
   ],
   "source": [
    "print(tryFeatures(lambda a: {'len':len(a), 'last':a[-2:], 'trim':a[-1:], 'start':a[:3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32c7f978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.955213133640553, 0.736)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryFeatures(lambda a: {'len':len(a), 'last':a[-2:], 'trim':a[-1:], 'start':a[:3]},nltk.classify.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643c6f8",
   "metadata": {},
   "source": [
    "Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5bb49ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.372\n",
      "             2          -0.38613        0.818\n",
      "             3          -0.32632        0.844\n",
      "             4          -0.29786        0.857\n",
      "             5          -0.28027        0.862\n",
      "             6          -0.26781        0.868\n",
      "             7          -0.25825        0.871\n",
      "             8          -0.25054        0.875\n",
      "             9          -0.24412        0.879\n",
      "            10          -0.23864        0.882\n",
      "            11          -0.23389        0.885\n",
      "            12          -0.22972        0.886\n",
      "            13          -0.22600        0.887\n",
      "            14          -0.22267        0.889\n",
      "            15          -0.21967        0.890\n",
      "            16          -0.21693        0.891\n",
      "            17          -0.21443        0.892\n",
      "            18          -0.21213        0.892\n",
      "            19          -0.21000        0.893\n",
      "            20          -0.20803        0.894\n",
      "            21          -0.20620        0.894\n",
      "            22          -0.20450        0.894\n",
      "            23          -0.20290        0.895\n",
      "            24          -0.20140        0.895\n",
      "            25          -0.19999        0.895\n",
      "            26          -0.19866        0.896\n",
      "            27          -0.19740        0.896\n",
      "            28          -0.19622        0.896\n",
      "            29          -0.19509        0.897\n",
      "            30          -0.19402        0.897\n",
      "            31          -0.19300        0.898\n",
      "            32          -0.19203        0.898\n",
      "            33          -0.19111        0.898\n",
      "            34          -0.19023        0.898\n",
      "            35          -0.18938        0.897\n",
      "            36          -0.18858        0.898\n",
      "            37          -0.18780        0.898\n",
      "            38          -0.18706        0.898\n",
      "            39          -0.18635        0.898\n",
      "            40          -0.18566        0.898\n",
      "            41          -0.18501        0.898\n",
      "            42          -0.18437        0.899\n",
      "            43          -0.18376        0.899\n",
      "            44          -0.18317        0.899\n",
      "            45          -0.18260        0.899\n",
      "            46          -0.18205        0.899\n",
      "            47          -0.18152        0.899\n",
      "            48          -0.18101        0.899\n",
      "            49          -0.18052        0.899\n",
      "            50          -0.18004        0.899\n",
      "            51          -0.17957        0.899\n",
      "            52          -0.17912        0.899\n",
      "            53          -0.17868        0.899\n",
      "            54          -0.17826        0.899\n",
      "            55          -0.17785        0.899\n",
      "            56          -0.17745        0.899\n",
      "            57          -0.17706        0.899\n",
      "            58          -0.17668        0.899\n",
      "            59          -0.17631        0.899\n",
      "            60          -0.17596        0.899\n",
      "            61          -0.17561        0.900\n",
      "            62          -0.17527        0.900\n",
      "            63          -0.17494        0.900\n",
      "            64          -0.17462        0.900\n",
      "            65          -0.17431        0.900\n",
      "            66          -0.17400        0.900\n",
      "            67          -0.17370        0.900\n",
      "            68          -0.17341        0.900\n",
      "            69          -0.17313        0.900\n",
      "            70          -0.17285        0.900\n",
      "            71          -0.17258        0.900\n",
      "            72          -0.17232        0.900\n",
      "            73          -0.17206        0.900\n",
      "            74          -0.17181        0.900\n",
      "            75          -0.17156        0.900\n",
      "            76          -0.17132        0.900\n",
      "            77          -0.17108        0.900\n",
      "            78          -0.17085        0.900\n",
      "            79          -0.17063        0.900\n",
      "            80          -0.17041        0.900\n",
      "            81          -0.17019        0.900\n",
      "            82          -0.16998        0.900\n",
      "            83          -0.16977        0.900\n",
      "            84          -0.16957        0.900\n",
      "            85          -0.16937        0.900\n",
      "            86          -0.16918        0.900\n",
      "            87          -0.16898        0.900\n",
      "            88          -0.16880        0.900\n",
      "            89          -0.16861        0.900\n",
      "            90          -0.16843        0.900\n",
      "            91          -0.16826        0.900\n",
      "            92          -0.16808        0.900\n",
      "            93          -0.16791        0.900\n",
      "            94          -0.16774        0.900\n",
      "            95          -0.16758        0.900\n",
      "            96          -0.16742        0.900\n",
      "            97          -0.16726        0.900\n",
      "            98          -0.16710        0.900\n",
      "            99          -0.16695        0.900\n",
      "         Final          -0.16680        0.900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9004896313364056, 0.828)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryFeatures(lambda a: {'len':len(a), 'last':a[-2:], 'trim':a[-1:], 'start':a[:3]},nltk.classify.MaxentClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab19527",
   "metadata": {},
   "source": [
    "Once you are\n",
    "satisfied with your classifier, check its final performance on the test set.\n",
    "How does the performance on the test set compare to the performance on the dev-test set? Is this what\n",
    "you'd expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816abb61",
   "metadata": {},
   "source": [
    "Looking at the results, a descision tree classifier over fits the data getting 95% accuracy on the training set but only 73.6% on the test set, while a naive bayes classifier does surprisingly well, attaining 90% accuracy on the 100th try. This suggests we use it for the final check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abc2fd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8609559279950342, 0.838)\n"
     ]
    }
   ],
   "source": [
    "print(tryFeatures(lambda a: {'len':len(a), 'last':a[-2:], 'trim':a[-1:], 'start':a[:3]}, final =True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312fe7e1",
   "metadata": {},
   "source": [
    "This does quite well, actually better than devtest (83.8% vs 81.6%). Normally one would expect a regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ec5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
